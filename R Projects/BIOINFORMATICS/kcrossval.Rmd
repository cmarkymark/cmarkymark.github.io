---
title: "K-Cross Validation"
author: "Charles Marks"
date: "December 8, 2018"
output: html_document
---

## In This Document

Contained within in is the code to run 5-fold cross validation utilizing a logisitic regression.  The details of implementation can be found within.

```{r global options}
library(tidyverse)
library(tableone)
library(PerformanceAnalytics)
library(psych)
options(digits = 2)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

## Uploading and Cleaning the Final Dataset

### Loading the Data

```{r dataset}

df <- read.csv("Dec8_Dataset.csv", header=TRUE)

```

### Exclusion Criteria

So, now we need to exclude people based on certain factors.  There are two primary exclusion criteria, the first being that patients must have been in care in the UC system 6 months prior to their surgery (ie we dont want people who just came to UC for surgery, as they will skew the results towards non-significance)

```{r pressure, echo=FALSE}

clean_data <- data.frame(matrix(nrow=0,ncol=ncol(df))) #this will be our final dataset
colnames(clean_data) <- colnames(df) #set the column names 

surgery_exclude_data <- data.frame(matrix(nrow=0,ncol=ncol(df))) #this will contain all patients excluded because they didn't have 6 months of records prior to their first surgery
colnames(surgery_exclude_data) <- colnames(df)

newpatient_exclude_data <- data.frame(matrix(nrow=0,ncol=ncol(df))) #this will contain non-surgery patients with less than six months of data
colnames(newpatient_exclude_data) <- colnames(df)

no_vital_data_exclude_data <- data.frame(matrix(nrow=0,ncol=ncol(df))) #this will contain all patients with no vital records
colnames(no_vital_data_exclude_data) <- colnames(df)

for(patient_num in 1:nrow(df)) #loop through all patients in the uploaded dataset
{ 
  if(!is.na(df$first_surgery_date[patient_num]) && !is.na(df$first_vitals_contact_date[patient_num])) #if patient has had surgery and has vital records
  {
    time_test <- difftime(df$first_surgery_date[patient_num], df$first_vitals_contact_date[patient_num], units = "days") #check the time difference between first vital contact and first surgery
    if(time_test > 180) #if length is greater than 6 months (ie 180 days), include
    {
      
      clean_data <- rbind(clean_data, df[patient_num,])
    } else {surgery_exclude_data <- rbind(surgery_exclude_data, df[patient_num,])}
  } 
  else if(is.na(df$first_surgery_date[patient_num]) && !is.na(df$first_vitals_contact_date[patient_num])) #for non-surgery patients
  {
    time_test2 <- difftime(as.Date("11/01/2018","%m/%d/%Y"), df$first_vitals_contact_date[patient_num], units = "days")
    if(time_test2 > 180)
    {
     clean_data <- rbind(clean_data, df[patient_num,])
    } else {
      newpatient_exclude_data <- rbind(newpatient_exclude_data, df[patient_num,])
    }
  } else
  {
    no_vital_data_exclude_data <- rbind(no_vital_data_exclude_data, df[patient_num,])
  }
}



```



### Imputing Missing Data

NOTE: All variables we imputed we decided to exclude from final analyses, hence why they are all commented out.  The blood pressure standard deviation variables are reflecting on a similar thing as the mean, min, and max variables combined.  Too much data was missing for alcohol use.  Smoking status and BMI did not come up as significant in early runs of the model, so they were excluded.

```{r impute}


## systolic_sd 30 NA

#clean_data$systolic_sd[is.na(clean_data$systolic_sd)] <- mean(clean_data$systolic_sd, na.rm = TRUE)

## diastolic_sd 30 NA

#clean_data$diastolic_sd[is.na(clean_data$diastolic_sd)] <- mean(clean_data$diastolic_sd, na.rm = TRUE)

## BMI mean 4 NA

#clean_data$BMI_mean[is.na(clean_data$BMI_mean)] <- median(clean_data$BMI_mean, na.rm = TRUE)
# attempts at imputing messed up analyses for some reason

## BMI max 3 NA (median)
#clean_data$BMI_max[is.na(clean_data$BMI_max)] <- median(clean_data$BMI_max, na.rm = TRUE)

## BMImin 3 NA (median)
#clean_data$BMI_min[is.na(clean_data$BMI_min)] <- median(clean_data$BMI_min, na.rm = TRUE)

## alcohol use (12 NAs)
## we will not imput given categorical nature, unclear how this will skew the results
## if it is not significant in initial analyses we will simply exclude from final analyses 

## smoking status (1 NA)
```

## Table One

Here is the descriptive statistics, stratified by history of glaucoma surgery.  Rows from this can be taken to present a final descriptive table, if so desired.  Descriptive table might not be overly meaningful tho...

```{r tableone}



tone_vars = colnames(clean_data)
tone_vars[12] <- NA
tone_vars[28] <- NA

tone <- tableone::CreateTableOne(vars = tone_vars, strata = c("any_glaucoma_surgey") ,data =  clean_data)
tone #this prints out the descriptive statistics, stratified by ever needing surgery

```

##Checking for Bivariate Correlations

```{r Bivariate, warning=FALSE}
bi.final <- data.frame(matrix(nrow = 0, ncol = 3))
for(i in 3:ncol(clean_data))
{
if(i == 11 || i == 12 || i == 22 || i == 23 || i == 24 || i == 25 || i == 26 ||i == 28 || i == 135 || i == 130 || i == 123 || i == 109 || i == 104 || i == 92 || i == 84 ||  i == 78 || i == 54 || i == 53){} ## this messy code removes the columns which contained data we didn't want to check or simply couldn't (do to 100% response for both variables)
  else{
iv <- colnames(clean_data)[i] 
bi.model <- glm (any_glaucoma_surgey ~ get(iv), data = clean_data, family = binomial(link="logit"))
#summary(age)
bi.results <- exp(cbind(OR = coef(bi.model), confint(bi.model)))
rownames(bi.results)[2] <- colnames(clean_data)[i]
bi.final <- rbind(bi.final, bi.results)
}
}

# this table represents all variables found to be significant and their OR
bi.signif <- bi.final[which(bi.final$`2.5 %` > 1 | bi.final$`97.5 %`<1),]
```


## Creating the five groups for cross-validation

So, now we will move into the cross-validation.  Given the smaller sample size we shall do five fold and thus we need to split the popuation randommly into five groups.  This randomization is done below.

```{r fivegroups}
#create a vector with the appropriate number of 1,2,3,4,5
values <- rep(1:5, length.out=391)
#randomly sort this vector
random <- sample(values)
#add this vector to the data, essentially assigning each row a random group
clean_data$cv_group <- random

```

## Defining Our Five Groups
So now we need to define our 5 training-test sets, which is done in the next code chunk

```{r define groups}

train.one <- clean_data[which(clean_data$cv_group!= 1),]
test.one <- clean_data[which(clean_data$cv_group== 1),]

train.two <- clean_data[which(clean_data$cv_group!= 2),]
test.two <- clean_data[which(clean_data$cv_group== 2),]

train.three <- clean_data[which(clean_data$cv_group!= 3),]
test.three <- clean_data[which(clean_data$cv_group== 3),]

train.four <- clean_data[which(clean_data$cv_group!= 4),]
test.four <- clean_data[which(clean_data$cv_group== 4),]

train.five <- clean_data[which(clean_data$cv_group!= 5),]
test.five <- clean_data[which(clean_data$cv_group== 5),]

```

## Running Cross Val

So, now we shall train the 5 models.  We will run a stepwise, bidirectional regression to determine the final model (ie will be unique for each of the models) and then run the final model with the selected results.  We will then pull out the AORs, AUC score, and plot the ROC curve.  We will choose the model with the best performing AUROC score.  (future efforts we shall report the average score of all 5)

### Test 1

```{r test 1, include=FALSE}

model.null.one = glm(any_glaucoma_surgey ~ 1, 
                 data=train.one,
                 family = binomial(link="logit")
                 )

model.full.one = glm(any_glaucoma_surgey ~ Age + Gender +systolic_max + systolic_min + systolic_mean  + diastolic_max + diastolic_min + diastolic_mean +pulse_min + pulse_max + pulse_mean  +ever_hospitalized + days_hospitalized + CHF + PVD + Stroke + Dementia + Pulmonary + LiverMild + DM + DMcx  + Renal + Cancer + Mets + med_class.Analgesics_._non.opioids + med_class.Analgesics_._opioids  +  med_class.Anti.rheumatic +  med_class.Antianxiety_agents  + med_class.Antiasthmatic + med_class.Anticoagulants+med_class.Anticonvulsant+med_class.Antidepressants+med_class.Antidiabetic+med_class.Antiemetics+med_class.Antihyperlipidemic+med_class.Antihypertensive+med_class.Beta_blockers+med_class.Calcium_blockers+med_class.Corticosteroids+med_class.Cough.Cold+med_class.Decongestants+med_class.Dermatological+med_class.Diuretics+med_class.Laxatives+med_class.Macrolide_antibiotics+med_class.Misc._antiinfectives+med_class.Ophthalmic+med_class.Ulcer_drugs, 
                 data=train.one,
                 family = binomial(link="logit")
                 )

step.results.one <- step(model.null.one,
     scope = list(upper=model.full.one),
             direction="both",
             test="Chisq",
             data=clean_data)

final.model.one <- eval(step.results.one$call)

lr.one.pr <- predict(final.model.one, test.one, type="response") # this sequence used to plot the ROC Curve
lr.one.pred <- prediction(lr.one.pr,test.one$any_glaucoma_surgey)
lr.one.perf <- performance(lr.one.pred,"tpr","fpr")

plot(lr.one.perf,main="ROC Curve for Logistic Regression",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")

```

### Test 2

```{r test 2, include=FALSE}

model.null.two = glm(any_glaucoma_surgey ~ 1, 
                 data=train.two,
                 family = binomial(link="logit")
                 )

model.full.two = glm(any_glaucoma_surgey ~ Age + Gender +systolic_max + systolic_min + systolic_mean  + diastolic_max + diastolic_min + diastolic_mean  +pulse_min + pulse_max + pulse_mean  +ever_hospitalized + days_hospitalized + CHF + PVD + Stroke + Dementia + Pulmonary + LiverMild + DM + DMcx  + Renal + Cancer + Mets + med_class.Analgesics_._non.opioids + med_class.Analgesics_._opioids  +  med_class.Anti.rheumatic +  med_class.Antianxiety_agents  + med_class.Antiasthmatic + med_class.Anticoagulants+med_class.Anticonvulsant+med_class.Antidepressants+med_class.Antidiabetic+med_class.Antiemetics+med_class.Antihyperlipidemic+med_class.Antihypertensive+med_class.Beta_blockers+med_class.Calcium_blockers+med_class.Corticosteroids+med_class.Cough.Cold+med_class.Decongestants+med_class.Dermatological+med_class.Diuretics+med_class.Laxatives+med_class.Macrolide_antibiotics+med_class.Misc._antiinfectives+med_class.Ophthalmic+med_class.Ulcer_drugs, 
                 data=train.two,
                 family = binomial(link="logit")
                 )

step.results.two <- step(model.null.two,
     scope = list(upper=model.full.two),
             direction="both",
             test="Chisq",
             data=clean_data)

final.model.two <- eval(step.results.two$call)

lr.two.pr <- predict(final.model.two, test.two, type="response")
lr.two.pred <- prediction(lr.two.pr,test.two$any_glaucoma_surgey)
lr.two.perf <- performance(lr.two.pred,"tpr","fpr")

plot(lr.two.perf,main="ROC Curve for Logistic Regression",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")


```

#### Extra Code Snippet

Sorry this is kind of out of place, but this code was utilized to determine the optimal cut point of the model and to determine the sensitivity, specificity, and accuracy of the model at said cut point

```{r get sensitivity and specificity}
opt.cut = function(perf, pred){
    cut.ind = mapply(FUN=function(x, y, p){
        d = (x - 0)^2 + (y-1)^2
        ind = which(d == min(d))
        c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
            cutoff = p[[ind]])
    }, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(lr.two.perf, lr.two.pred))


acc.perf = performance(lr.two.pred, measure = "acc")
plot(acc.perf)

ind = which.max( slot(acc.perf, "y.values")[[1]] )
acc = slot(acc.perf, "y.values")[[1]][ind]
cutoff = slot(acc.perf, "x.values")[[1]][ind]
print(c(accuracy= acc, cutoff = cutoff))

```

### Test 3

```{r test 3, include=FALSE}

model.null.three = glm(any_glaucoma_surgey ~ 1, 
                 data=train.three,
                 family = binomial(link="logit")
                 )

model.full.three = glm(any_glaucoma_surgey ~ Age + Gender +systolic_max + systolic_min + systolic_mean +  diastolic_max + diastolic_min + diastolic_mean +pulse_min + pulse_max + pulse_mean  +ever_hospitalized + days_hospitalized + CHF + PVD + Stroke + Dementia + Pulmonary + LiverMild + DM + DMcx  + Renal + Cancer + Mets + med_class.Analgesics_._non.opioids + med_class.Analgesics_._opioids  +  med_class.Anti.rheumatic +  med_class.Antianxiety_agents  + med_class.Antiasthmatic + med_class.Anticoagulants+med_class.Anticonvulsant+med_class.Antidepressants+med_class.Antidiabetic+med_class.Antiemetics+med_class.Antihyperlipidemic+med_class.Antihypertensive+med_class.Beta_blockers+med_class.Calcium_blockers+med_class.Corticosteroids+med_class.Cough.Cold+med_class.Decongestants+med_class.Dermatological+med_class.Diuretics+med_class.Laxatives+med_class.Macrolide_antibiotics+med_class.Misc._antiinfectives+med_class.Ophthalmic+med_class.Ulcer_drugs, 
                 data=train.three,
                 family = binomial(link="logit")
                 )

step.results.three <- step(model.null.three,
     scope = list(upper=model.full.three),
             direction="both",
             test="Chisq",
             data=clean_data)


final.model.three <- eval(step.results.three$call)

lr.three.pr <- predict(final.model.three, test.three, type="response") # this sequence used to plot the ROC Curve
lr.three.pred <- prediction(lr.three.pr,test.three$any_glaucoma_surgey)
lr.three.perf <- performance(lr.three.pred,"tpr","fpr")

plot(lr.three.perf,main="ROC Curve for Logistic Regression",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")

```

### Test 4

```{r test 4, include=FALSE}

model.null.four = glm(any_glaucoma_surgey ~ 1, 
                 data=train.four,
                 family = binomial(link="logit")
                 )

model.full.four = glm(any_glaucoma_surgey ~ Age + Gender +systolic_max + systolic_min + systolic_mean +  diastolic_max + diastolic_min + diastolic_mean +pulse_min + pulse_max + pulse_mean  +ever_hospitalized + days_hospitalized + CHF + PVD + Stroke + Dementia + Pulmonary + LiverMild + DM + DMcx  + Renal + Cancer + Mets + med_class.Analgesics_._non.opioids + med_class.Analgesics_._opioids  +  med_class.Anti.rheumatic +  med_class.Antianxiety_agents  + med_class.Antiasthmatic + med_class.Anticoagulants+med_class.Anticonvulsant+med_class.Antidepressants+med_class.Antidiabetic+med_class.Antiemetics+med_class.Antihyperlipidemic+med_class.Antihypertensive+med_class.Beta_blockers+med_class.Calcium_blockers+med_class.Corticosteroids+med_class.Cough.Cold+med_class.Decongestants+med_class.Dermatological+med_class.Diuretics+med_class.Laxatives+med_class.Macrolide_antibiotics+med_class.Misc._antiinfectives+med_class.Ophthalmic+med_class.Ulcer_drugs, 
                 data=train.four,
                 family = binomial(link="logit")
                 )

step.results.four <- step(model.null.four,
     scope = list(upper=model.full.four),
             direction="both",
             test="Chisq",
             data=clean_data)

final.model.four <- eval(step.results.four$call)

lr.four.pr <- predict(final.model.four, test.four, type="response") # this sequence used to plot the ROC Curve
lr.four.pred <- prediction(lr.four.pr,test.four$any_glaucoma_surgey)
lr.four.perf <- performance(lr.four.pred,"tpr","fpr")

plot(lr.four.perf,main="ROC Curve for Logistic Regression",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")

```

### Test 5

```{r test 5, include=FALSE}

model.null.five = glm(any_glaucoma_surgey ~ 1, 
                 data=train.five,
                 family = binomial(link="logit")
                 )

model.full.five = glm(any_glaucoma_surgey ~ Age + Gender +systolic_max + systolic_min + systolic_mean + diastolic_max + diastolic_min + diastolic_mean +pulse_min + pulse_max + pulse_mean  +ever_hospitalized + days_hospitalized + CHF + PVD + Stroke + Dementia + Pulmonary + LiverMild + DM + DMcx  + Renal + Cancer + Mets + med_class.Analgesics_._non.opioids + med_class.Analgesics_._opioids  +  med_class.Anti.rheumatic +  med_class.Antianxiety_agents  + med_class.Antiasthmatic + med_class.Anticoagulants+med_class.Anticonvulsant+med_class.Antidepressants+med_class.Antidiabetic+med_class.Antiemetics+med_class.Antihyperlipidemic+med_class.Antihypertensive+med_class.Beta_blockers+med_class.Calcium_blockers+med_class.Corticosteroids+med_class.Cough.Cold+med_class.Decongestants+med_class.Dermatological+med_class.Diuretics+med_class.Laxatives+med_class.Macrolide_antibiotics+med_class.Misc._antiinfectives+med_class.Ophthalmic+med_class.Ulcer_drugs, 
                 data=train.five,
                 family = binomial(link="logit")
                 )

step.results.five <- step(model.null.five,
     scope = list(upper=model.full.five),
             direction="both",
             test="Chisq",
             data=clean_data)


final.model.five <- eval(step.results.five$call)

lr.five.pr <- predict(final.model.five, test.five, type="response") # this sequence used to plot the ROC Curve
lr.five.pred <- prediction(lr.five.pr,test.five$any_glaucoma_surgey)
lr.five.perf <- performance(lr.five.pred,"tpr","fpr")

plot(lr.five.perf,main="ROC Curve for Logistic Regression",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")

```

### COMAPRE ROC

Here we will compute and display the ROC of each of the five models so we may choose the best performing

```{r roc comapre}

rf.one.auc <- performance(rf.one.pred,"auc")@y.values[[1]]
rf.two.auc <- performance(rf.two.pred,"auc")@y.values[[1]]
rf.three.auc <- performance(rf.three.pred,"auc")@y.values[[1]]
rf.four.auc <- performance(rf.four.pred,"auc")@y.values[[1]]
rf.five.auc <- performance(rf.five.pred,"auc")@y.values[[1]]

print(rf.one.auc)
print(rf.two.auc)
print(rf.three.auc)
print(rf.four.auc)
print(rf.five.auc)

```

## Results of Best Model

So now we will choose the best model and look at the AORS and some evaluation metrics

```{r looking at the best}

results <- round(exp(cbind(OR = coef(final.model.five), confint(final.model.five))),2)
results # this will returns the Odds Ratios and the confidence intervals

```

## Evaluating This Model

### Discrimination (C-Statistic aka AUC)

We can go back up to the code for running the models to see the code for plotting the AUC

### Caibration (Hoslem-Lemeshow)

This shall return the Hoslem-Lemeshow score and print a calibration plot, displaying confidence intervals

```{r calibration}

library(generalhoslem)
logitgof(test.five$any_glaucoma_surgey, test.five$probs, g = 5)
library(gbm)
calibrate.plot(test.five$any_glaucoma_surgey, test.five$probs)
```

## Finally, We Will Save Everything

```{r Saving Docs}

final_test_set <- test.five
final_training_set <- train.five
final_regression_equation <- "glm(formula = any_glaucoma_surgey ~ med_class.Ophthalmic + med_class.Analgesics_._non.opioids + systolic_min + days_hospitalized + med_class.Antihyperlipidemic + systolic_mean + med_class.Macrolide_antibiotics + med_class.Calcium_blockers + med_class.Cough.Cold + med_class.Decongestants + med_class.Anticoagulants + Mets, family = binomial(link = 'logit'), data = train.five)"
final_ORs <- results
final_model_coefficients <- final.model.five$coefficients

write.csv(final_test_set, "Final_Test_Set_Dec8.csv")
write.csv(final_training_set, "Final_Training_Set_Dec8.csv")
write.file(final_regression_equation, "final_regression_equation.txt")
write.csv(final_ORs, "final_logistic_regression_results.csv")
write.csv(final_model_coefficients, "final_model_coefficients.csv")
```




